import numpy as np
from scipy.stats import norm, t
from scipy.signal import correlate
from sklearn.ensemble import ExtraTreesClassifier

def crps_per_marginal(scenarios: np.ndarray, y_true: np.ndarray):
    """
    scenarios: np.ndarray of shape (n_scenarios, T)
    y_true: np.ndarray of shape (T,)
    
    Returns:
        crps: np.ndarray of shape (T,), CRPS per marginal (e.g., per hour)
    """
    # term 1: average absolute error between scenario and true value
    term1 = np.mean(np.abs(scenarios - y_true[None, :]), axis=0)  # shape: (T,)

    # term 2: average pairwise absolute difference among scenarios
    diffs = np.abs(scenarios[:, None, :] - scenarios[None, :, :])  # shape: (n, n, T)
    term2 = 0.5 * np.mean(diffs, axis=(0, 1))  # shape: (T,)

    crps = term1 - term2 
    return crps

def crps_batch_per_marginal(scenarios: np.ndarray, y_true: np.ndarray, calculate_mean: bool = True):
    """
    scenarios: np.ndarray of shape (n_scenarios, batch, T)
    y_true: np.ndarray of shape (batch, T)

    Returns:
        crps: np.ndarray of shape (T,), which is the mean crps over all batches
    """
    crps_list = []
    for i in range(y_true.shape[0]):
        crps_list.append(crps_per_marginal(scenarios[:, i, :], y_true[i, :]))
    crps = np.mean(crps_list, axis=0)
    return np.mean(crps) if calculate_mean else crps

def energy_score(scenarios: np.ndarray, y_true: np.ndarray):
    """
    scenarios: np.ndarray of shape (n_samples, T)
    y_true: np.ndarray of shape (T,)

    Returns:
        Energy score (float)
    """

    term_1 = np.linalg.norm(scenarios - y_true[None, :], axis=1).mean()
    term_2 = np.linalg.norm(scenarios[:, None, :] - scenarios[None, :, :], axis=2).mean()
    return term_1 - 0.5 * term_2

def energy_score_per_batch(scenarios: np.ndarray, y_true: np.ndarray):
    """
    scenarios: np.ndarray of shape (n_samples, batch, T)
    y_true: np.ndarray of shape (batch, T)

    Returns:
        Energy score (float)
    """
    energy_score_list = []
    for i in range(y_true.shape[0]):
        energy_score_list.append(energy_score(scenarios[:, i, :], y_true[i, :]))
    return np.mean(energy_score_list)

def variogram_score(scenarios: np.ndarray, y_true: np.ndarray, gamma=0.5):
    """
    scenarios: np.ndarray of shape (n_samples, T)
    y_true: np.ndarray of shape (T,)
    gamma: float, usually 0.5 or 1

    Returns:
        Variogram Score (float)
    """
    diffs_true = np.abs(y_true[None, :] - y_true[:, None]) ** gamma  # (T, T)
    diffs_sample = np.abs(scenarios[:, :, None] - scenarios[:, None, :]) ** gamma  # (n_samples, T, T)
    expected_diffs = np.mean(diffs_sample, axis=0)  # (T, T)

    score = np.sum((diffs_true - expected_diffs) ** 2)
    return score

def variogram_score_per_batch(scenarios: np.ndarray, y_true: np.ndarray, gamma=0.5):
    """
    scenarios: (n_samples, batch, T)
    y_true: (batch, T)

    Returns:
        Mean variogram score over batch
    """
    scores = [
        variogram_score(scenarios[:, i, :], y_true[i, :], gamma)
        for i in range(y_true.shape[0])
    ]
    return np.mean(scores)

def quantile_score_per_marginal(quantiles: np.ndarray, y_true: np.ndarray, q: int = 50):
    """
    quantiles: np.ndarray of shape (99, T) a set of 99 quantiles generated by scenarios
    y_true: np.ndarray of shape (T,)
    q: int (1-99) the qth quantile

    Returns:
        Quantile Score: np.ndarray of shape (T,)
    """
    assert quantiles.shape[0] == 99
    assert 1 <= q <= 99
    diff = quantiles[q, :] - y_true
    return np.where(diff > 0, (1-q/100) * diff, -(q/100) * diff)

def quantile_score_per_batch(quantiles: np.ndarray, y_true: np.ndarray, q: int = 50):
    """
    quantiles: np.ndarray of shape (99, batch, T) a set of 99 quantiles generated by scenarios
    y_true: np.ndarray of shape (batch, T)
    q: int (1-99) the qth quantile

    Returns:
        Quantile Score: np.ndarray of shape (99,). The quantile score averaged over batches and time periods
    """
    quantile_score_q = []
    for i in range(y_true.shape[0]):
        quantile_score_q.append(quantile_score_per_marginal(quantiles[:, i, :], y_true[i, :], q).mean())

    return np.mean(quantile_score_q)

def quantile_score_averaged(quantiles: np.ndarray, y_true: np.ndarray):
    return np.mean([quantile_score_per_batch(quantiles, y_true, q) for q in range(1, 100)])

def quantile_score_averaged_fast(quantiles: np.ndarray, y_true: np.ndarray) -> float:
    """
    quantiles: np.ndarray of shape (99, B, T)
    y_true: np.ndarray of shape (B, T)

    Returns:
        float: averaged quantile score over 1â€“99
    """
    qs = np.arange(1, 100).reshape(-1, 1, 1) / 100  # (99, 1, 1)
    forecast = quantiles  # (99, B, T)
    y = y_true[None, :, :]  # (1, B, T)
    diff = forecast - y  # (99, B, T)

    loss = np.where(diff >= 0, (1 - qs) * diff, -qs * diff)
    return loss.mean()

def diebold_mariano_test(loss_model_g, loss_model_h, h=1):
    d = loss_model_g - loss_model_h
    T = len(d)
    d_mean = np.mean(d)
    d_centered = d - d_mean

    autocov = correlate(d_centered, d_centered, mode='full', method='fft') / T
    mid = len(autocov) // 2
    gamma = autocov[mid - h: mid + h + 1]  # lags from -h to +h

    # Long-run variance estimator (Newey-West with truncation lag h)
    f_d = gamma[0] + 2 * np.sum(gamma[1:])  # sum of autocovariances

    DM_stat = d_mean / np.sqrt(f_d / T)

    # Harvey et al. (1997) small-sample correction
    correction_factor = np.sqrt((T + 1 - 2 * h + h * (h - 1)/T) / T)
    DM_corrected = DM_stat * correction_factor

    # Two-sided p-value
    p_value = 2 * t.cdf(-np.abs(DM_corrected), df=T - 1)

    return DM_corrected, p_value

def fit_trees(X, y, **kwargs):
    max_depth = kwargs.get('max_depth', 10)
    n_estiamtors = kwargs.get('n_estimators', 100)
    clf = ExtraTreesClassifier(max_depth=max_depth, n_estimators=n_estiamtors, n_jobs=-1, random_state=42)
    clf.fit(X, y)
    return clf
